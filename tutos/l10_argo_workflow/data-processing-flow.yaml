# Output parameters provide a general mechanism to use the result of a step as a parameter rather than as an artifact. 
# This allows you to use the result from any type of step, not just a script, for conditional tests, loops, and arguments
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: data-processing-flow-
spec:
  entrypoint: master-task
  templates:
  # dag template which will coordinates the whole workflow
  - name: master-task
    dag:
      tasks:
      # task 1-1 generate random number
      - name: extract-data-from-db
        template: python-extractor
      # task 1-2 generate random number
      - name: extract-data-from-s3
        template: python-extractor
      # task 1-3 generate random number
      - name: web-scraping
        template: python-extractor

      # task 2 write the three generated random numbers to a file
      - name: save-data-to-datalake
        dependencies: [extract-data-from-db,extract-data-from-s3,web-scraping]
        template: output-param
        arguments:
          parameters: 
          - name: random-val-1
          # the value is from task "generate-random-value-1", as the template of this task is a script. So the the output is in outputs.result
            value: "{{tasks.extract-data-from-db.outputs.result}}"
          - name: random-val-2
          # the value is from task "generate-random-value-2", as the template of this task is a script. So the the output is in outputs.result
            value: "{{tasks.extract-data-from-s3.outputs.result}}"
          - name: random-val-3
          # the value is from task "generate-random-value", as the template of this task is a script. So the the output is in outputs.result
            value: "{{tasks.web-scraping.outputs.result}}"

     # task 3 is a sub master which contains multiple steps
      - name: transform-data
        dependencies: [save-data-to-datalake]
        template: transform-value-template
        arguments:
          parameters: 
          - name: all-val
          # the value is from task "generate-random-value-1", as the template of this task is a script. So the the output is in outputs.result
            value: "{{tasks.save-data-to-datalake.outputs.parameters.random-val}}"

    # task 4 
      - name: generate-result
        dependencies: [transform-data]
        template: spark-worker
        arguments:
          parameters:
          - name: id
            value: "generate-result"
          - name: message
            value: "generate result"

    # task 5
      - name: save-result
        dependencies: [generate-result]
        template: spark-worker
        arguments:
          parameters: [{name: message, value: "save-result"},{name: id,value: "save-result"}]
    
# list of worker template which runs actual job on pods
# template of taks 1
  - name: python-extractor
    script:
      image: python:alpine3.8
      command: [python]
      source: |
        import random
        i = random.randint(1, 100)
        print(i)

# template of task 2 
  - name: output-param
    inputs:
      parameters:
      - name: random-val-1
      - name: random-val-2
      - name: random-val-3
    container:
      image: busybox
      command: [sh, -c]
      args: ["echo {{inputs.parameters.random-val-1}} {{inputs.parameters.random-val-2}} {{inputs.parameters.random-val-3}} > /tmp/value.txt"]  # generate the content of hello_world.txt
      volumeMounts:
        - name: out
          mountPath: /tmp
    outputs:
      parameters:
      - name: random-val     # name of output parameter
        valueFrom:
          path: /tmp/value.txt    # set the output object random-val-param to the contents of file value.txt

# template of task 3
# This template contains steps
  - name: transform-value-template
    inputs:
      parameters:
      - name: all-val
    steps:
    - - name: step-a           
        template: bash-worker
        arguments:
          parameters:
          # Pass the hello-param output from the generate-parameter step as the message input to print-message
          - name: message
            value: "{{inputs.parameters.all-val}}"
    - - name: step-b
        template: spark-worker
        arguments:
          parameters: [{name: message, value: "eliminate null cells"},{name: id,value: "transform data, step b"}]
      - name: step-c
        template: spark-worker
        arguments:
          parameters: [{name: message, value: "merge column"},{name: id,value: "transform data, step c"}]

# template of task 3, step1 
  - name: bash-worker
    inputs:
      parameters:
      - name: message
    container:
      image: alpine:latest
      command: [sh, -c]
      args: ["echo result was: {{inputs.parameters.message}}"]

# template for general worker
  - name: spark-worker
    inputs:
      parameters:
      - name: message
      - name: id
    container:
      image: busybox
      command: [echo, "This is worker {{inputs.parameters.id}}, the job {{inputs.parameters.message}} is completed"]  

  volumes:
      - name: out
        emptyDir: { }