apiVersion: v1
kind: ConfigMap
metadata:
  name: atlas-config
data:
  atlas-application.properties: |

    #########  Graph Database Configs  #########

    atlas.graph.storage.backend=hbase2
    atlas.graph.storage.hbase.table=apache_atlas_janus

    #Hbase
    #For standalone mode , specify localhost
    #for distributed mode, specify zookeeper quorum here
    atlas.graph.storage.hostname=localhost
    atlas.graph.storage.hbase.regions-per-server=1
    atlas.graph.storage.lock.wait-time=10000

    # Gremlin Query Optimizer
    #
    # Enables rewriting gremlin queries to maximize performance. This flag is provided as
    # a possible way to work around any defects that are found in the optimizer until they
    # are resolved.
    #atlas.query.gremlinOptimizerEnabled=true

    # Delete handler
    #
    # This allows the default behavior of doing "soft" deletes to be changed.
    #
    # Allowed Values:
    # org.apache.atlas.repository.store.graph.v1.SoftDeleteHandlerV1 - all deletes are "soft" deletes
    # org.apache.atlas.repository.store.graph.v1.HardDeleteHandlerV1 - all deletes are "hard" deletes
    #
    #atlas.DeleteHandlerV1.impl=org.apache.atlas.repository.store.graph.v1.SoftDeleteHandlerV1

    # Entity audit repository
    #
    # This allows the default behavior of logging entity changes to hbase to be changed.
    #
    # Allowed Values:
    # org.apache.atlas.repository.audit.HBaseBasedAuditRepository - log entity changes to hbase
    # org.apache.atlas.repository.audit.CassandraBasedAuditRepository - log entity changes to cassandra
    # org.apache.atlas.repository.audit.NoopEntityAuditRepository - disable the audit repository
    #
    atlas.EntityAuditRepository.impl=org.apache.atlas.repository.audit.HBaseBasedAuditRepository

    # if Cassandra is used as a backend for audit from the above property, uncomment and set the following
    # properties appropriately. If using the embedded cassandra profile, these properties can remain
    # commented out.
    # atlas.EntityAuditRepository.keyspace=atlas_audit
    # atlas.EntityAuditRepository.replicationFactor=1


    # Graph Search Index
    atlas.graph.index.search.backend=solr

    #Solr
    #Solr cloud mode properties
    atlas.graph.index.search.solr.mode=cloud
    atlas.graph.index.search.solr.zookeeper-url=localhost:2181
    atlas.graph.index.search.solr.zookeeper-connect-timeout=60000
    atlas.graph.index.search.solr.zookeeper-session-timeout=60000
    atlas.graph.index.search.solr.wait-searcher=true

    #Solr http mode properties
    #atlas.graph.index.search.solr.mode=http
    #atlas.graph.index.search.solr.http-urls=http://localhost:8983/solr

    # Solr-specific configuration property
    atlas.graph.index.search.max-result-set-size=150

    #########  Import Configs  #########
    #atlas.import.temp.directory=/temp/import

    #########  Notification Configs  #########
    atlas.notification.embedded=true
    atlas.kafka.data=${sys:atlas.home}/data/kafka
    atlas.kafka.zookeeper.connect=localhost:9026
    atlas.kafka.bootstrap.servers=localhost:9027
    atlas.kafka.zookeeper.session.timeout.ms=400
    atlas.kafka.zookeeper.connection.timeout.ms=200
    atlas.kafka.zookeeper.sync.time.ms=20
    atlas.kafka.auto.commit.interval.ms=1000
    atlas.kafka.hook.group.id=atlas

    atlas.kafka.enable.auto.commit=false
    atlas.kafka.auto.offset.reset=earliest
    atlas.kafka.session.timeout.ms=30000
    atlas.kafka.offsets.topic.replication.factor=1
    atlas.kafka.poll.timeout.ms=1000

    atlas.notification.create.topics=true
    atlas.notification.replicas=1
    atlas.notification.topics=ATLAS_HOOK,ATLAS_ENTITIES
    atlas.notification.log.failed.messages=true
    atlas.notification.consumer.retry.interval=500
    atlas.notification.hook.retry.interval=1000
    # Enable for Kerberized Kafka clusters
    #atlas.notification.kafka.service.principal=kafka/_HOST@EXAMPLE.COM
    #atlas.notification.kafka.keytab.location=/etc/security/keytabs/kafka.service.keytab

    ## Server port configuration
    #atlas.server.http.port=21000
    #atlas.server.https.port=21443

    #########  Security Properties  #########

    # SSL config
    atlas.enableTLS=false

    #truststore.file=/path/to/truststore.jks
    #cert.stores.credential.provider.path=jceks://file/path/to/credentialstore.jceks

    #following only required for 2-way SSL
    #keystore.file=/path/to/keystore.jks

    # Authentication config

    atlas.authentication.method.kerberos=false
    atlas.authentication.method.file=true

    #### ldap.type= LDAP or AD
    atlas.authentication.method.ldap.type=none

    #### user credentials file
    atlas.authentication.method.file.filename=${sys:atlas.home}/conf/users-credentials.properties

    ### groups from UGI
    #atlas.authentication.method.ldap.ugi-groups=true

   
    #########  JAAS Configuration ########

    #atlas.jaas.KafkaClient.loginModuleName = com.sun.security.auth.module.Krb5LoginModule
    #atlas.jaas.KafkaClient.loginModuleControlFlag = required
    #atlas.jaas.KafkaClient.option.useKeyTab = true
    #atlas.jaas.KafkaClient.option.storeKey = true
    #atlas.jaas.KafkaClient.option.serviceName = kafka
    #atlas.jaas.KafkaClient.option.keyTab = /etc/security/keytabs/atlas.service.keytab
    #atlas.jaas.KafkaClient.option.principal = atlas/_HOST@EXAMPLE.COM

    #########  Server Properties  #########
    atlas.rest.address=http://localhost:21000
    # If enabled and set to true, this will run setup steps when the server starts
    #atlas.server.run.setup.on.start=false

    #########  Entity Audit Configs  #########
    atlas.audit.hbase.tablename=apache_atlas_entity_audit
    atlas.audit.zookeeper.session.timeout.ms=1000
    atlas.audit.hbase.zookeeper.quorum=localhost:2181

    #########  High Availability Configuration ########
    atlas.server.ha.enabled=false
    #### Enabled the configs below as per need if HA is enabled #####
    #atlas.server.ids=id1
    #atlas.server.address.id1=localhost:21000
    #atlas.server.ha.zookeeper.connect=localhost:2181
    #atlas.server.ha.zookeeper.retry.sleeptime.ms=1000
    #atlas.server.ha.zookeeper.num.retries=3
    #atlas.server.ha.zookeeper.session.timeout.ms=20000
    ## if ACLs need to be set on the created nodes, uncomment these lines and set the values ##
    #atlas.server.ha.zookeeper.acl=<scheme>:<id>
    #atlas.server.ha.zookeeper.auth=<scheme>:<authinfo>



    ######### Atlas Authorization #########
    atlas.authorizer.impl=simple
    atlas.authorizer.simple.authz.policy.file=atlas-simple-authz-policy.json

    #########  Type Cache Implementation ########
    # A type cache class which implements
    # org.apache.atlas.typesystem.types.cache.TypeCache.
    # The default implementation is org.apache.atlas.typesystem.types.cache.DefaultTypeCache which is a local in-memory type cache.
    #atlas.TypeCache.impl=

    #########  Performance Configs  #########
    #atlas.graph.storage.lock.retries=10
    #atlas.graph.storage.cache.db-cache-time=120000

    #########  CSRF Configs  #########
    atlas.rest-csrf.enabled=true
    atlas.rest-csrf.browser-useragents-regex=^Mozilla.*,^Opera.*,^Chrome.*
    atlas.rest-csrf.methods-to-ignore=GET,OPTIONS,HEAD,TRACE
    atlas.rest-csrf.custom-header=X-XSRF-HEADER

    ############ KNOX Configs ################
    #atlas.sso.knox.browser.useragent=Mozilla,Chrome,Opera
    #atlas.sso.knox.enabled=true
    #atlas.sso.knox.providerurl=https://<knox gateway ip>:8443/gateway/knoxsso/api/v1/websso
    #atlas.sso.knox.publicKey=

    ############ Atlas Metric/Stats configs ################
    # Format: atlas.metric.query.<key>.<name>
    atlas.metric.query.cache.ttlInSecs=900
    #atlas.metric.query.general.typeCount=
    #atlas.metric.query.general.typeUnusedCount=
    #atlas.metric.query.general.entityCount=
    #atlas.metric.query.general.tagCount=
    #atlas.metric.query.general.entityDeleted=
    #
    #atlas.metric.query.entity.typeEntities=
    #atlas.metric.query.entity.entityTagged=
    #
    #atlas.metric.query.tags.entityTags=

    #########  Compiled Query Cache Configuration  #########

    # The size of the compiled query cache.  Older queries will be evicted from the cache
    # when we reach the capacity.

    #atlas.CompiledQueryCache.capacity=1000

    # Allows notifications when items are evicted from the compiled query
    # cache because it has become full.  A warning will be issued when
    # the specified number of evictions have occurred.  If the eviction
    # warning threshold <= 0, no eviction warnings will be issued.

    #atlas.CompiledQueryCache.evictionWarningThrottle=0


    #########  Full Text Search Configuration  #########

    #Set to false to disable full text search.
    #atlas.search.fulltext.enable=true

    #########  Gremlin Search Configuration  #########

    #Set to false to disable gremlin search.
    atlas.search.gremlin.enable=false

    #########  UI Configuration ########

    atlas.ui.default.version=v1
    atlas.ui.editable.entity.types=*

  atlas-env.sh: |
    #!/usr/bin/env bash
    #
    # The java implementation to use. If JAVA_HOME is not found we expect java and jar to be in path
    #export JAVA_HOME=

    # any additional java opts you want to set. This will apply to both client and server operations
    #export ATLAS_OPTS=

    # any additional java opts that you want to set for client only
    #export ATLAS_CLIENT_OPTS=

    # java heap size we want to set for the client. Default is 1024MB
    #export ATLAS_CLIENT_HEAP=

    # any additional opts you want to set for atlas service.
    #export ATLAS_SERVER_OPTS=

    # indicative values for large number of metadata entities (equal or more than 10,000s)
    #export ATLAS_SERVER_OPTS="-server -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+PrintTenuringDistribution -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=dumps/atlas_server.hprof -Xloggc:logs/gc-worker.log -verbose:gc -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1m -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCTimeStamps"

    # java heap size we want to set for the atlas server. Default is 1024MB
    #export ATLAS_SERVER_HEAP=

    # indicative values for large number of metadata entities (equal or more than 10,000s) for JDK 8
    #export ATLAS_SERVER_HEAP="-Xms15360m -Xmx15360m -XX:MaxNewSize=5120m -XX:MetaspaceSize=100M -XX:MaxMetaspaceSize=512m"

    # What is is considered as atlas home dir. Default is the base locaion of the installed software
    #export ATLAS_HOME_DIR=

    # Where log files are stored. Defatult is logs directory under the base install location
    #export ATLAS_LOG_DIR=

    # Where pid files are stored. Defatult is logs directory under the base install location
    #export ATLAS_PID_DIR=

    # where the atlas titan db data is stored. Defatult is logs/data directory under the base install location
    #export ATLAS_DATA_DIR=

    # Where do you want to expand the war file. By Default it is in /server/webapp dir under the base install dir.
    #export ATLAS_EXPANDED_WEBAPP_DIR=

    # indicates whether or not a local instance of HBase should be started for Atlas
    export MANAGE_LOCAL_HBASE=true

    # indicates whether or not a local instance of Solr should be started for Atlas
    export MANAGE_LOCAL_SOLR=true

    # indicates whether or not cassandra is the embedded backend for Atlas
    export MANAGE_EMBEDDED_CASSANDRA=false

    # indicates whether or not a local instance of Elasticsearch should be started for Atlas
    export MANAGE_LOCAL_ELASTICSEARCH=false